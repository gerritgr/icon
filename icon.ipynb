{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOCPWay+eQ+YRWhxAZmFRX5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gerritgr/icon/blob/main/icon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŽ¯ icon: Fast Simulation of Epidemics on Coevolving Networks"
      ],
      "metadata": {
        "id": "2Y_31Q2lT6WV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ],
      "metadata": {
        "id": "k1JWzDIOULmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import random\n",
        "from itertools import combinations\n",
        "from scipy.stats import expon\n",
        "import pandas as pd\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "import itertools\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Simulation time limit set to 120 minutes\n",
        "SIM_TIME_LIMIT_IN_S = 60 * 120"
      ],
      "metadata": {
        "id": "bWChsIfoUlaz"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utils"
      ],
      "metadata": {
        "id": "9SyQU0xBUmHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute the epidemic threshold, too slow for very large graphs :(\n",
        "# Thus, we use  the average degree as a simple proxy\n",
        "def compute_epidemic_threshold_or_avg_degree(G, fast_approx=True):\n",
        "    if fast_approx:\n",
        "        avg_degree = 2 * G.number_of_edges() / G.number_of_nodes()\n",
        "        return 1 / avg_degree\n",
        "\n",
        "    A = nx.adjacency_matrix(G).todense()\n",
        "    eigenvalues = np.linalg.eigvals(A)\n",
        "    largest_eigenvalue = max(eigenvalues.real)\n",
        "    return 1 / largest_eigenvalue\n",
        "\n",
        "\n",
        "# Create a random geometric graph based on target degeee\n",
        "def create_geometric_graph(n, target_degree=10, seed=42):\n",
        "    r = np.sqrt(target_degree / (n * np.pi))\n",
        "    G = nx.random_geometric_graph(n, r, seed=seed)\n",
        "    avg_degree = sum(dict(G.degree()).values()) / n\n",
        "    return G\n"
      ],
      "metadata": {
        "id": "ppe2ucLEUJ8N"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline (naive)"
      ],
      "metadata": {
        "id": "SeIvXqwMZX0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to run the baseline epidemic simulation\n",
        "def run_baseline_simulation(\n",
        "        G, node_to_state_map, filename, beta_rate, alpha_rate,\n",
        "        b_rate, a_rate,\n",
        "        horizon, save_graph_state, graph_type):\n",
        "\n",
        "    # Ensure all nodes in node_to_state_map are added to the graph\n",
        "    for node in node_to_state_map:\n",
        "        if node not in G.nodes():\n",
        "            G.add_node(node)\n",
        "\n",
        "    n = len(G.nodes())  # Number of nodes in the graph\n",
        "\n",
        "    # Initial count of infected nodes\n",
        "    infected_nodes_count = sum(1 for state in node_to_state_map.values() if state == 'I')\n",
        "\n",
        "    # Milestones to record simulation progress (we store the results when milestone is passed)\n",
        "    milestones = np.linspace(0, horizon, 101)\n",
        "    milestone_index = 0\n",
        "\n",
        "    # Lists to store results at each milestone\n",
        "    infected_nodes_records = []\n",
        "    avg_degree_records = []\n",
        "    accepted_events_records = []\n",
        "    rejected_events_records = []  # Empty since no rejections in baseline\n",
        "    edge_list_records = [] if save_graph_state else None\n",
        "\n",
        "    # Initialize accepted event counter (no rejected events happen in this baseline)\n",
        "    accepted_events = 0\n",
        "\n",
        "    # Start measuring runtime\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Simulation loop with progress bar\n",
        "    t = 0\n",
        "    with tqdm(total=horizon, desc=f\"Simulating {graph_type} graph with {n} nodes\", dynamic_ncols=True) as pbar:\n",
        "        while t < horizon:\n",
        "            # Record results at milestones\n",
        "            while milestone_index < len(milestones) and t >= milestones[milestone_index]:\n",
        "                infected_nodes_records.append(infected_nodes_count)\n",
        "                avg_degree_records.append(2 * len(G.edges()) / n)  # Formula do compute avg. degree\n",
        "                accepted_events_records.append(accepted_events)\n",
        "                rejected_events_records.append(0)  # No rejections in baseline\n",
        "                if save_graph_state: # Use ; because we save as .csv\n",
        "                    edge_list_records.append(';'.join([f\"({u},{v})\" for u, v in G.edges()]))\n",
        "                milestone_index += 1\n",
        "\n",
        "            # Prepare list of possible events and their jump times\n",
        "            events = []\n",
        "\n",
        "            # Edge events (transmission or disconnection)\n",
        "            for v1, v2 in itertools.combinations(G.nodes(), 2):\n",
        "                if G.has_edge(v1, v2):\n",
        "                    # SI edge: Transmission\n",
        "                    if node_to_state_map[v1] != node_to_state_map[v2]:\n",
        "                        jump_time = expon(scale=1 / beta_rate).rvs()\n",
        "                        events.append((jump_time, 'transmission', min(v1, v2), max(v1, v2)))\n",
        "                    # II edge: Disconnection\n",
        "                    elif node_to_state_map[v1] == 'I' and node_to_state_map[v2] == 'I':\n",
        "                        jump_time = expon(scale=1 / b_rate).rvs()\n",
        "                        events.append((jump_time, 'disconnection', min(v1, v2), max(v1, v2)))\n",
        "                else:\n",
        "                    # SS nodes: Connection event\n",
        "                    if node_to_state_map[v1] == 'S' and node_to_state_map[v2] == 'S':\n",
        "                        jump_time = expon(scale=1 / a_rate).rvs()\n",
        "                        events.append((jump_time, 'connection', min(v1, v2), max(v1, v2)))\n",
        "\n",
        "            # Recovery events\n",
        "            for v in G.nodes():\n",
        "                if node_to_state_map[v] == 'I':\n",
        "                    jump_time = expon(scale=1 / alpha_rate).rvs()\n",
        "                    events.append((jump_time, 'recovery', v, None))\n",
        "\n",
        "            # Find the event with the smallest jump time\n",
        "            events.sort(key=lambda x: x[0])\n",
        "            if events:\n",
        "                min_time, event_type, v1, v2 = events[0]\n",
        "\n",
        "            # Apply the event\n",
        "            t += min_time\n",
        "            if time.time() - start_time > SIM_TIME_LIMIT_IN_S or len(events) == 0:\n",
        "                t += horizon* 2 # Enforce termination\n",
        "            if t >= horizon:\n",
        "                pbar.n = horizon # Set progress bar to final value H\n",
        "                pbar.refresh()\n",
        "                break\n",
        "\n",
        "            # Update progress bar\n",
        "            pbar.n = t\n",
        "            pbar.refresh()\n",
        "\n",
        "            # Process the event\n",
        "            if event_type == 'transmission':\n",
        "                infected_nodes_count += 1\n",
        "                # Transmission event: one node infects the other\n",
        "                node_to_state_map[v2] = 'I'\n",
        "            elif event_type == 'disconnection':\n",
        "                # Disconnection event: remove the edge\n",
        "                G.remove_edge(v1, v2)\n",
        "            elif event_type == 'connection':\n",
        "                # Connection event: add edge between SS nodes\n",
        "                G.add_edge(v1, v2)\n",
        "            elif event_type == 'recovery':\n",
        "                # Recovery event: node becomes susceptible\n",
        "                if infected_nodes_count != 1:\n",
        "                    node_to_state_map[v1] = 'S'\n",
        "                    infected_nodes_count -= 1\n",
        "\n",
        "            accepted_events += 1\n",
        "\n",
        "    # Record remaining milestones if the time horizon is reached\n",
        "    while milestone_index < len(milestones):\n",
        "        infected_nodes_records.append(infected_nodes_count)\n",
        "        avg_degree_records.append(2 * len(G.edges()) / n)\n",
        "        accepted_events_records.append(accepted_events)\n",
        "        rejected_events_records.append(0)\n",
        "        if save_graph_state:\n",
        "            edge_list_records.append(';'.join([f\"({u},{v})\" for u, v in G.edges()]))\n",
        "        milestone_index += 1\n",
        "\n",
        "    # Measure the runtime in milliseconds\n",
        "    run_time_in_ms = (time.time() - start_time) * 1000\n",
        "\n",
        "    # Prepare data for saving\n",
        "    data = {\n",
        "        \"experiment_id\": [experiment_num] * len(milestones),\n",
        "        \"Time\": milestones,\n",
        "        \"Avg_degree\": avg_degree_records,\n",
        "        \"Infected_nodes\": infected_nodes_records,\n",
        "        \"Accepted_events\": accepted_events_records,\n",
        "        \"Rejected_events\": rejected_events_records,\n",
        "        \"Run_time_in_ms\": [run_time_in_ms] * len(milestones),\n",
        "        \"Number_of_nodes\": [n] * len(milestones),\n",
        "        \"graph_type\": [graph_type] * len(milestones)\n",
        "    }\n",
        "\n",
        "    # Save results to CSV\n",
        "    results_df = pd.DataFrame(data)\n",
        "    results_df.to_csv(filename, index=False)\n",
        "\n",
        "    print(f\"Baseline simulation for {graph_type} graph with {n} nodes complete. Results saved to {filename}.\")\n"
      ],
      "metadata": {
        "id": "kauvBKf6ZY-y"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline (fast)"
      ],
      "metadata": {
        "id": "Mdw7Iz-HZb4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_baseline_simulation_fast(\n",
        "        G, node_to_state_map, filename, beta_rate, alpha_rate,\n",
        "        b_rate, a_rate,\n",
        "        horizon, save_graph_state, graph_type):\n",
        "\n",
        "    # Add missing nodes from node_to_state_map to the graph\n",
        "    for node in node_to_state_map:\n",
        "        if node not in G.nodes():\n",
        "            G.add_node(node)\n",
        "\n",
        "    # Initial state: count infected nodes\n",
        "    infected_nodes_count = sum(1 for state in node_to_state_map.values() if state == 'I')\n",
        "\n",
        "    # Initialize data structures with ordered node pairs\n",
        "    SS_nonedge = [\n",
        "        (min(u, v), max(u, v)) for u in G.nodes() for v in G.nodes()\n",
        "        if u < v and node_to_state_map[u] == 'S' and node_to_state_map[v] == 'S' and not G.has_edge(u, v)\n",
        "    ]\n",
        "    SI_edge = [\n",
        "        (min(u, v), max(u, v)) for u, v in G.edges()\n",
        "        if (node_to_state_map[u] == 'S' and node_to_state_map[v] == 'I') or (node_to_state_map[u] == 'I' and node_to_state_map[v] == 'S')\n",
        "    ]\n",
        "    I_node = [v for v in G.nodes() if node_to_state_map[v] == 'I']\n",
        "    II_edge = [\n",
        "        (min(u, v), max(u, v)) for u, v in G.edges() if node_to_state_map[u] == 'I' and node_to_state_map[v] == 'I'\n",
        "    ]\n",
        "\n",
        "    # Ensure consistency of the initial data structures\n",
        "    for u, v in SI_edge:\n",
        "        assert node_to_state_map[u] != node_to_state_map[v], \"Initial inconsistent SI_edge list\"\n",
        "    for u, v in II_edge:\n",
        "        assert node_to_state_map[u] == 'I' and node_to_state_map[v] == 'I', \"Initial inconsistent II_edge list\"\n",
        "    for u, v in SS_nonedge:\n",
        "        assert node_to_state_map[u] == 'S' and node_to_state_map[v] == 'S' and not G.has_edge(u, v), \"Initial inconsistent SS_nonedge list\"\n",
        "\n",
        "    # Milestones\n",
        "    milestones = np.linspace(0, horizon, 101)\n",
        "    milestone_index = 0\n",
        "\n",
        "    # Lists to store results at milestones\n",
        "    infected_nodes_records = []\n",
        "    avg_degree_records = []\n",
        "    accepted_events_records = []\n",
        "    rejected_events_records = []  # No rejections in baseline simulation\n",
        "    edge_list_records = [] if save_graph_state else None\n",
        "\n",
        "    # Initialize counter for accepted events\n",
        "    accepted_events = 0\n",
        "\n",
        "    # Start measuring the runtime\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Simulation loop with progress bar\n",
        "    t = 0\n",
        "    n = len(G.nodes())  # Total number of nodes\n",
        "    with tqdm(total=horizon, desc=f\"Simulating {graph_type} graph with {n} nodes\", dynamic_ncols=True) as pbar:\n",
        "        while t < horizon:\n",
        "            # Record results at milestones\n",
        "            while milestone_index < len(milestones) and t >= milestones[milestone_index]:\n",
        "                infected_nodes_records.append(infected_nodes_count)\n",
        "                avg_degree_records.append(2 * len(G.edges()) / n)  # Average degree\n",
        "                accepted_events_records.append(accepted_events)\n",
        "                rejected_events_records.append(0)  # No rejections in baseline\n",
        "                if save_graph_state:\n",
        "                    edge_list_records.append(';'.join([f\"({u},{v})\" for u, v in G.edges()]))\n",
        "                milestone_index += 1\n",
        "\n",
        "            # Calculate jump times for each event type\n",
        "            time_to_transmission = np.random.exponential(1 / (len(SI_edge) * beta_rate)) if SI_edge else float('inf')\n",
        "            time_to_disconnection = np.random.exponential(1 / (len(II_edge) * b_rate)) if II_edge else float('inf')\n",
        "            time_to_connection = np.random.exponential(1 / (len(SS_nonedge) * a_rate)) if SS_nonedge else float('inf')\n",
        "            time_to_recovery = np.random.exponential(1 / (len(I_node) * alpha_rate)) if I_node else float('inf')\n",
        "\n",
        "            # Determine the event with the shortest jump time\n",
        "            min_time = min(time_to_transmission, time_to_disconnection, time_to_connection, time_to_recovery)\n",
        "\n",
        "            # Apply the event with the shortest jump time\n",
        "            t += min_time\n",
        "            if time.time() - start_time > SIM_TIME_LIMIT_IN_S:\n",
        "                t += horizon* 2  # Stop simulation if it exceeds time limit\n",
        "            if t >= horizon:\n",
        "                pbar.n = horizon # Set progress bar to final value H\n",
        "                pbar.refresh()\n",
        "                break\n",
        "\n",
        "            # Update progress bar\n",
        "            pbar.n = t\n",
        "            pbar.refresh()\n",
        "\n",
        "            # Handle the events based on the minimum jump time\n",
        "            if min_time == time_to_transmission:\n",
        "                # Transmission: Choose a random SI edge\n",
        "                u, v = random.choice(SI_edge)\n",
        "                new_infected = u if node_to_state_map[u] == 'S' else v\n",
        "                node_to_state_map[new_infected] = 'I'\n",
        "                infected_nodes_count += 1\n",
        "                I_node.append(new_infected)\n",
        "\n",
        "                # Update II edges with the newly infected node\n",
        "                for neighbor in G.neighbors(new_infected):\n",
        "                    if node_to_state_map[neighbor] == 'I':\n",
        "                        II_edge.append((min(new_infected, neighbor), max(new_infected, neighbor)))\n",
        "\n",
        "                # Update SS_nonedge and SI_edge lists\n",
        "                SS_nonedge = [(x, y) for x, y in SS_nonedge if node_to_state_map[x] == 'S' and node_to_state_map[y] == 'S']\n",
        "                SI_edge = [\n",
        "                    (a, b) for a, b in SI_edge\n",
        "                    if (node_to_state_map[a] == 'I' and node_to_state_map[b] == 'S') or (node_to_state_map[a] == 'S' and node_to_state_map[b] == 'I')\n",
        "                ]\n",
        "                for neighbor in G.neighbors(new_infected):\n",
        "                    if node_to_state_map[neighbor] == 'S':\n",
        "                        SI_edge.append((min(new_infected, neighbor), max(new_infected, neighbor)))\n",
        "\n",
        "            elif min_time == time_to_disconnection:\n",
        "                # Disconnection: Remove a random II edge\n",
        "                u, v = random.choice(II_edge)\n",
        "                G.remove_edge(u, v)\n",
        "                II_edge.remove((u, v))\n",
        "\n",
        "            elif min_time == time_to_connection:\n",
        "                # Connection: Add a random SS non-edge\n",
        "                u, v = random.choice(SS_nonedge)\n",
        "                G.add_edge(u, v)\n",
        "                SS_nonedge.remove((u, v))\n",
        "\n",
        "            elif min_time == time_to_recovery:\n",
        "                # Recovery: Choose a random infected node to recover\n",
        "                if infected_nodes_count != 1:\n",
        "                    v = random.choice(I_node)\n",
        "                    node_to_state_map[v] = 'S'\n",
        "                    infected_nodes_count -= 1\n",
        "                    I_node.remove(v)\n",
        "\n",
        "                    # Update SI_edge and II_edge\n",
        "                    for neighbor in G.neighbors(v):\n",
        "                        if node_to_state_map[neighbor] == 'S':\n",
        "                            SI_edge.remove((min(v, neighbor), max(v, neighbor)))\n",
        "                        elif node_to_state_map[neighbor] == 'I':\n",
        "                            II_edge.remove((min(v, neighbor), max(v, neighbor)))\n",
        "                            SI_edge.append((min(v, neighbor), max(v, neighbor)))\n",
        "\n",
        "                    # Update SS_nonedge\n",
        "                    for other_node in G.nodes():\n",
        "                        if other_node != v and node_to_state_map[other_node] == 'S' and not G.has_edge(v, other_node):\n",
        "                            SS_nonedge.append((min(v, other_node), max(v, other_node)))\n",
        "\n",
        "            accepted_events += 1\n",
        "\n",
        "    # Ensure remaining milestones are recorded if the time horizon is reached\n",
        "    while milestone_index < len(milestones):\n",
        "        infected_nodes_records.append(infected_nodes_count)\n",
        "        avg_degree_records.append(2 * len(G.edges()) / n)  # Average degree\n",
        "        accepted_events_records.append(accepted_events)\n",
        "        rejected_events_records.append(0)  # No rejections in baseline\n",
        "        if save_graph_state:\n",
        "            edge_list_records.append(';'.join([f\"({u},{v})\" for u, v in G.edges()]))\n",
        "        milestone_index += 1\n",
        "\n",
        "    # Measure the runtime in milliseconds\n",
        "    run_time_in_ms = (time.time() - start_time) * 1000\n",
        "\n",
        "    # Prepare data for saving\n",
        "    data = {\n",
        "        \"experiment_id\": [experiment_num] * len(milestones),\n",
        "        \"Time\": milestones,\n",
        "        \"Avg_degree\": avg_degree_records,\n",
        "        \"Infected_nodes\": infected_nodes_records,\n",
        "        \"Accepted_events\": accepted_events_records,\n",
        "        \"Rejected_events\": rejected_events_records,  # No rejections in baseline\n",
        "        \"Run_time_in_ms\": [run_time_in_ms] * len(milestones),\n",
        "        \"Number_of_nodes\": [n] * len(milestones),\n",
        "        \"graph_type\": [graph_type] * len(milestones)\n",
        "    }\n",
        "\n",
        "    # Save results to CSV\n",
        "    results_df = pd.DataFrame(data)\n",
        "    results_df.to_csv(filename, index=False)\n",
        "\n",
        "    print(f\"Fast Baseline simulation for {graph_type} graph with {n} nodes complete. Results saved to {filename}.\")\n"
      ],
      "metadata": {
        "id": "z6E3pHiVZZRw"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸŽ¯ icon: our Method"
      ],
      "metadata": {
        "id": "YiXmgrG7ZfOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to run the epidemic simulation\n",
        "def run_simulation(G, node_to_state_map, filename, beta_rate, alpha_rate,\n",
        "                   b_rate, a_rate,\n",
        "                   horizon, save_graph_state, graph_type):\n",
        "\n",
        "    # Ensure all nodes from node_to_state_map are present in the graph\n",
        "    for node in node_to_state_map:\n",
        "        if node not in G.nodes():\n",
        "            G.add_node(node)\n",
        "\n",
        "    # Get the total number of nodes\n",
        "    n = len(G.nodes())\n",
        "\n",
        "    # Count the initial number of infected nodes\n",
        "    infected_nodes_count = sum(1 for state in node_to_state_map.values() if state == 'I')\n",
        "\n",
        "    # Create a unique edge list with (v, v') where v < v'\n",
        "    edge_list = [(min(u, v), max(u, v)) for u, v in G.edges()]\n",
        "    edge_list = list(set(edge_list))\n",
        "\n",
        "    # Calculate the initial average degree\n",
        "    avg_degree = 2 * len(edge_list) / n\n",
        "\n",
        "    # Determine upper bounds for various rates\n",
        "    upper_bound_edge = max(beta_rate, b_rate)\n",
        "    upper_bound_node = alpha_rate\n",
        "    upper_bound_possible_pairs = n * (n - 1) // 2\n",
        "    upper_bound_non_connected = a_rate\n",
        "\n",
        "    # Milestones for recording results during the simulation\n",
        "    milestones = np.linspace(0, horizon, 101)\n",
        "    milestone_index = 0\n",
        "\n",
        "    # Lists to store results at each milestone\n",
        "    infected_nodes_records = []\n",
        "    avg_degree_records = []\n",
        "    accepted_events_records = []\n",
        "    rejected_events_records = []\n",
        "    edge_list_records = [] if save_graph_state else None\n",
        "\n",
        "    # Counters for accepted and rejected events\n",
        "    accepted_events = 0\n",
        "    rejected_events = 0\n",
        "\n",
        "    # Start measuring the runtime\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Simulation loop with progress bar\n",
        "    t = 0\n",
        "    with tqdm(total=horizon, desc=f\"Simulating {graph_type} graph with {n} nodes\", dynamic_ncols=True) as pbar:\n",
        "        while t < horizon:\n",
        "            # Record results at milestones\n",
        "            while milestone_index < len(milestones) and t >= milestones[milestone_index]:\n",
        "                infected_nodes_records.append(infected_nodes_count)\n",
        "                avg_degree_records.append(avg_degree)\n",
        "                accepted_events_records.append(accepted_events)\n",
        "                rejected_events_records.append(rejected_events)\n",
        "                if save_graph_state:\n",
        "                    edge_list_records.append(';'.join([f\"({u},{v})\" for u, v in edge_list]))\n",
        "                milestone_index += 1\n",
        "\n",
        "            # Rates based on the current state of the system\n",
        "            rate_edge = len(edge_list) * upper_bound_edge\n",
        "            rate_node = n * upper_bound_node\n",
        "            rate_non_connected = upper_bound_possible_pairs * upper_bound_non_connected\n",
        "\n",
        "            # Generate residence times for each type of event\n",
        "            time_to_edge_event = expon(scale=1/rate_edge).rvs() if rate_edge > 0 else float('inf')\n",
        "            time_to_node_event = expon(scale=1/rate_node).rvs() if rate_node > 0 else float('inf')\n",
        "            time_to_non_connected_event = expon(scale=1/rate_non_connected).rvs() if rate_non_connected > 0 else float('inf')\n",
        "\n",
        "            # Determine which event happens next\n",
        "            times = [time_to_edge_event, time_to_node_event, time_to_non_connected_event]\n",
        "            event_index = np.argmin(times)\n",
        "            t += times[event_index]\n",
        "\n",
        "            # Stop the simulation if time limit is exceeded or no more infected nodes\n",
        "            if time.time() - start_time > SIM_TIME_LIMIT_IN_S or infected_nodes_count == 0:\n",
        "                t += horizon* 2\n",
        "\n",
        "            if t >= horizon:\n",
        "                pbar.n = horizon # Set progress bar to the final value H\n",
        "                pbar.refresh()\n",
        "                break\n",
        "\n",
        "            # Update the progress bar\n",
        "            pbar.n = t\n",
        "            pbar.refresh()\n",
        "\n",
        "            # Process edge event (SI transmission or II disconnection)\n",
        "            if event_index == 0:\n",
        "                u, v = random.choice(edge_list)\n",
        "                if node_to_state_map[u] != node_to_state_map[v]:  # SI edge\n",
        "                    if random.random() < beta_rate / upper_bound_edge:\n",
        "                        if node_to_state_map[u] == 'I':\n",
        "                            node_to_state_map[v] = 'I'\n",
        "                        else:\n",
        "                            node_to_state_map[u] = 'I'\n",
        "                        infected_nodes_count += 1\n",
        "                        accepted_events += 1\n",
        "                    else:\n",
        "                        rejected_events += 1\n",
        "                elif node_to_state_map[u] == 'I' and node_to_state_map[v] == 'I':  # II edge\n",
        "                    if random.random() < b_rate / upper_bound_edge:\n",
        "                        edge_list.remove((u, v))\n",
        "                        avg_degree = 2 * len(edge_list) / n\n",
        "                        accepted_events += 1\n",
        "                    else:\n",
        "                        rejected_events += 1\n",
        "\n",
        "            # Process node event (recovery)\n",
        "            elif event_index == 1:\n",
        "                u = random.choice(list(G.nodes()))\n",
        "                if node_to_state_map[u] == 'I':\n",
        "                    if random.random() < alpha_rate/ upper_bound_node:\n",
        "                        if infected_nodes_count != 1:\n",
        "                            node_to_state_map[u] = 'S'\n",
        "                            infected_nodes_count -= 1\n",
        "                        accepted_events += 1\n",
        "                    else:\n",
        "                        rejected_events += 1\n",
        "                else:\n",
        "                    rejected_events += 1\n",
        "\n",
        "            # Process non-connected event (SS connection)\n",
        "            elif event_index == 2:\n",
        "                u, v = sorted(random.sample(range(n), 2))\n",
        "                if (u, v) not in edge_list and node_to_state_map[u] == 'S' and node_to_state_map[v] == 'S':\n",
        "                    if random.random() < a_rate / upper_bound_non_connected:\n",
        "                        edge_list.append((u, v))\n",
        "                        avg_degree = 2 * len(edge_list) / n\n",
        "                        accepted_events += 1\n",
        "                    else:\n",
        "                        rejected_events += 1\n",
        "                else:\n",
        "                    rejected_events += 1\n",
        "\n",
        "    # Ensure remaining milestones are recorded if the time horizon is reached\n",
        "    while milestone_index < len(milestones):\n",
        "        infected_nodes_records.append(infected_nodes_count)\n",
        "        avg_degree_records.append(avg_degree)\n",
        "        accepted_events_records.append(accepted_events)\n",
        "        rejected_events_records.append(rejected_events)\n",
        "        if save_graph_state:\n",
        "            edge_list_records.append(';'.join([f\"({u},{v})\" for u, v in edge_list]))\n",
        "        milestone_index += 1\n",
        "\n",
        "    # Measure the runtime in milliseconds\n",
        "    run_time_in_ms = (time.time() - start_time) * 1000\n",
        "\n",
        "    # Prepare the data for saving\n",
        "    data = {\n",
        "        \"experiment_id\": [experiment_num] * len(milestones),\n",
        "        \"Time\": milestones,\n",
        "        \"Avg_degree\": avg_degree_records,\n",
        "        \"Infected_nodes\": infected_nodes_records,\n",
        "        \"Accepted_events\": accepted_events_records,\n",
        "        \"Rejected_events\": rejected_events_records,\n",
        "        \"Run_time_in_ms\": [run_time_in_ms] * len(milestones),\n",
        "        \"Number_of_nodes\": [n] * len(milestones),\n",
        "        \"graph_type\": [graph_type] * len(milestones)\n",
        "    }\n",
        "\n",
        "    # Save results to CSV\n",
        "    results_df = pd.DataFrame(data)\n",
        "    if save_graph_state:\n",
        "        results_df[\"edge_list\"] = edge_list_records\n",
        "\n",
        "    results_df.to_csv(filename, index=False)\n",
        "\n",
        "    print(f\"Experiment {experiment_num} complete. Results saved to {filename}.\")\n"
      ],
      "metadata": {
        "id": "nbDCTqN3ZdTu"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Start Experiments"
      ],
      "metadata": {
        "id": "m58BZp42ZjvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model parameters\n",
        "prob_init_infected = 0.1\n",
        "beta_rate = 2.0 # transmission rate\n",
        "b_rate = 2.0 # edge disconnection rate\n",
        "a_star = 0.3 # rate for connection of SS edges\n",
        "alpha_rate= 1.0 # rate for recovery\n",
        "\n",
        "beta_func = lambda x: x * beta_rate # maps avg degree to beta\n",
        "a_rate_function = lambda n: a_star / n # maps number of nodes to a\n",
        "\n",
        "# Experiment parameters\n",
        "n_values = [10, 10**2, 10**3, 10**4, 10**5] # number of nodes\n",
        "experiment_num = 1\n",
        "save_graph_state_limit = 11  # Limit to save the graph state (edge_list) at each milestone\n",
        "experiments_per_n = 5\n",
        "graph_types = ['random', 'geometric', 'barabasi']\n",
        "random_seed = 42  #\n",
        "\n",
        "\n",
        "# Function to determine time horizon based on the number of nodes\n",
        "def H_func(n):\n",
        "    if n >= 10000:\n",
        "        return 0.1\n",
        "    if n >= 1000:\n",
        "        return 1.0\n",
        "    return 5.0\n",
        "\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "\n",
        "# Main simulation loop\n",
        "for n in n_values:\n",
        "    for graph_type in graph_types:\n",
        "        for _ in range(experiments_per_n):\n",
        "            print(\"Starting experiment...\")\n",
        "\n",
        "            # Generate the graph based on the specified type\n",
        "            if graph_type == 'random':\n",
        "                # Generate a connected random graph (ErdÅ‘sâ€“RÃ©nyi). Relax if too expensive.\n",
        "                for i in range(10):  # Try generating the graph multiple times\n",
        "                    target_degree = 5  # Average degree is 5\n",
        "                    G = nx.erdos_renyi_graph(n, target_degree / (n - 1), seed=42+i+experiment_num)\n",
        "                    if n > 1000 or nx.is_connected(G):\n",
        "                        break\n",
        "\n",
        "            elif graph_type == 'barabasi':\n",
        "                # Generate a BarabÃ¡siâ€“Albert graph\n",
        "                G = nx.barabasi_albert_graph(n, 5, seed=42+experiment_num)\n",
        "\n",
        "            elif graph_type == 'geometric':\n",
        "                # Generate a geometric graph\n",
        "                target_degree = 5\n",
        "                G = create_geometric_graph(n, target_degree=target_degree, seed=42+experiment_num)\n",
        "\n",
        "            print(f\"Graph generated with {G.number_of_nodes()} nodes.\")\n",
        "\n",
        "            # Calculate transmission rate, connection rate, and time horizon for concrete graph\n",
        "            beta_rate = beta_func(compute_epidemic_threshold_or_avg_degree(G))\n",
        "            a_rate = a_rate_function(n)\n",
        "            horizon= H_func(n)\n",
        "\n",
        "            # Initialize node states (S or I)\n",
        "            num_infected = int(n * prob_init_infected + 0.5)\n",
        "            assert num_infected > 0\n",
        "            infected_nodes = set(random.sample(list(G.nodes()), num_infected))\n",
        "            node_to_state_map = {node: 'I' if node in infected_nodes else 'S' for node in G.nodes()}\n",
        "\n",
        "            # Define the filename for saving results\n",
        "            filename = f'sis_simulation_results_{experiment_num:03d}_{n:010d}_nodes_{graph_type}.csv'\n",
        "\n",
        "            # Run the main simulation and save results\n",
        "            print(\"Running simulation...\")\n",
        "            save_graph_state = n <= save_graph_state_limit\n",
        "            run_simulation(copy.deepcopy(G), copy.deepcopy(node_to_state_map), filename, beta_rate, alpha_rate,\n",
        "                           b_rate, a_rate,\n",
        "                           horizon, save_graph_state, graph_type)\n",
        "\n",
        "            # Optionally run the baseline fast simulation if n <= 10,000\n",
        "            try:\n",
        "                if n <= 10000:\n",
        "                    print(\"Running baseline fast simulation...\")\n",
        "                    filename = f'sis_baselinefast_simulation_results_{experiment_num:03d}_{n:010d}_nodes_{graph_type}.csv'\n",
        "                    run_baseline_simulation_fast(copy.deepcopy(G), copy.deepcopy(node_to_state_map), filename, beta_rate, alpha_rate,\n",
        "                                                 b_rate, a_rate,\n",
        "                                                 horizon, save_graph_state, graph_type)\n",
        "            except Exception as e:\n",
        "                print(f\"Exception during baseline fast simulation: {e}\")\n",
        "\n",
        "            # Optionally run the baseline naive simulation if n <= 1,000\n",
        "            try:\n",
        "                if n <= 1000:\n",
        "                    print(\"Running baseline naive simulation...\")\n",
        "                    filename = f'sis_baselinenaive_simulation_results_{experiment_num:03d}_{n:010d}_nodes_{graph_type}.csv'\n",
        "                    run_baseline_simulation(copy.deepcopy(G), copy.deepcopy(node_to_state_map), filename, beta_rate, alpha_rate,\n",
        "                                            b_rate, a_rate,\n",
        "                                            horizon, save_graph_state, graph_type)\n",
        "            except Exception as e:\n",
        "                print(f\"Exception during baseline naive simulation: {e}\")\n",
        "\n",
        "            # Increment experiment number\n",
        "            experiment_num += 1\n"
      ],
      "metadata": {
        "id": "xc12KBxjx09f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotting Trajectories"
      ],
      "metadata": {
        "id": "2vl7-F4SZvAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seaborn style for publication-quality plots, without grid\n",
        "sns.set(style=\"white\", rc={\"axes.edgecolor\": \"0.0\", \"axes.linewidth\": 1.25})\n",
        "\n",
        "# Function to format plots for publication\n",
        "def format_plot(ax, title, xlabel, ylabel):\n",
        "    \"\"\"Format the plot for publication-ready figures.\"\"\"\n",
        "    ax.set_title(title, fontsize=25)\n",
        "    ax.set_xlabel(xlabel, fontsize=30)\n",
        "    ax.set_ylabel(ylabel, fontsize=30)\n",
        "    ax.tick_params(axis='both', which='major', labelsize=30, length=0)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "\n",
        "# Initialize dictionaries to store data and filenames\n",
        "data_dict = dict()\n",
        "filenames = dict()\n",
        "\n",
        "# Get all files matching the pattern\n",
        "files = glob.glob(\"sis_simulation_results_*.csv\")\n",
        "\n",
        "# Process each file and store data in the dictionaries\n",
        "for file in sorted(files):\n",
        "    print(file)\n",
        "    n = int(file.split(\"_\")[4])\n",
        "    graph_type = file.split(\"_\")[6].replace('.csv', '')\n",
        "\n",
        "    # Initialize lists if key doesn't exist\n",
        "    if (n, graph_type) not in data_dict:\n",
        "        data_dict[(n, graph_type)] = []\n",
        "    if (n, graph_type) not in filenames:\n",
        "        filenames[(n, graph_type)] = []\n",
        "\n",
        "    # Append data and filenames\n",
        "    data_dict[(n, graph_type)].append(pd.read_csv(file))\n",
        "    filenames[(n, graph_type)].append(file)\n",
        "\n",
        "# Define the styles: alternating between solid, dashed, and dotted lines\n",
        "styles = [\n",
        "    {\"linestyle\": \"-\", \"lw\": 4.0, 'alpha': 0.9},  # Solid line\n",
        "    {\"linestyle\": \"--\", \"lw\": 4.0, 'alpha': 0.9},  # Dashed line\n",
        "    {\"linestyle\": \":\", \"lw\": 4.0, 'alpha': 0.9},  # Dotted line\n",
        "    {\"linestyle\": \"-.\", \"lw\": 4.0, 'alpha': 0.9},  # Dash-dot line\n",
        "]\n",
        "\n",
        "# Plotting infection traces over time\n",
        "keys = sorted(list(data_dict.keys()))\n",
        "for (n, graph_type) in keys:\n",
        "    data = data_dict[(n, graph_type)]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Create a color palette (shades of blue)\n",
        "    palette = sns.color_palette(\"Blues\", len(data))\n",
        "\n",
        "    # Loop over each DataFrame in the list for (n, graph_type)\n",
        "    for i, df in enumerate(data):\n",
        "        style = styles[i % len(styles)]  # Cycle through the defined styles\n",
        "        plt.plot(df['Time'], df['Infected_nodes'], color=palette[i], **style)  # Different shades of blue\n",
        "\n",
        "    # Get the current axis and format the plot\n",
        "    ax = plt.gca()\n",
        "    format_plot(ax, f\"Prevalence ({graph_type.capitalize()} - {n})\", \"Time\", \"Number of Infected Nodes\")\n",
        "    plt.xlim(xmin=-0.05)\n",
        "    plt.ylim(ymin=-0.05)\n",
        "\n",
        "    # Save the figure to a PDF file\n",
        "    plt.savefig(f\"Infection_traces_{graph_type}_{n}.pdf\", bbox_inches='tight')\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "# Plotting average degree variation over time\n",
        "for (n, graph_type) in keys:\n",
        "    data = data_dict[(n, graph_type)]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Create a color palette (shades of red)\n",
        "    palette = sns.color_palette(\"Reds\", len(data))\n",
        "\n",
        "    # Loop over each DataFrame in the list for (n, graph_type)\n",
        "    for i, df in enumerate(data):\n",
        "        style = styles[i % len(styles)]  # Cycle through the defined styles\n",
        "        plt.plot(df['Time'], df['Avg_degree'], color=palette[i], **style)  # Different shades of red\n",
        "\n",
        "    # Get the current axis and format the plot\n",
        "    ax = plt.gca()\n",
        "    format_plot(ax, f\"Degree Variation ({graph_type.capitalize()} - {n})\", \"Time\", \"Average Degree\")\n",
        "    plt.xlim(xmin=-0.1)\n",
        "\n",
        "    # Save the figure to a PDF file\n",
        "    plt.savefig(f\"Avgdegree_traces_{graph_type}_{n}.pdf\", bbox_inches='tight')\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "V49e8y3_x4l9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotting Results"
      ],
      "metadata": {
        "id": "PdGZCrqQZy2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seaborn style for publication-quality plots, without grid\n",
        "sns.set(style=\"white\", rc={\"axes.edgecolor\": \"0.0\", \"axes.linewidth\": 1.25})\n",
        "\n",
        "# Function to format plots for publication\n",
        "def format_plot(ax, title, xlabel, ylabel):\n",
        "    \"\"\"Format the plot for publication-ready figures.\"\"\"\n",
        "    ax.set_title(title, fontsize=30)\n",
        "    ax.set_xlabel(xlabel, fontsize=30)\n",
        "    ax.set_ylabel(ylabel, fontsize=30)\n",
        "    ax.tick_params(axis='both', which='major', labelsize=30, length=0)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "\n",
        "# Initialize list to store data\n",
        "data_list = []\n",
        "\n",
        "# Get all files matching the pattern\n",
        "files = glob.glob(\"sis_simulation_results_*.csv\") + \\\n",
        "        glob.glob(\"sis_baselinefast_simulation_results_*.csv\") + \\\n",
        "        glob.glob(\"sis_baselinenaive_simulation_results_*.csv\")\n",
        "\n",
        "# Process each file and store data in the list\n",
        "for file in sorted(files):\n",
        "    print(file)\n",
        "    graph_type = file.split(\"_\")[-1].replace('.csv', '')\n",
        "    method = 'ours'  # Default method\n",
        "    if 'fast' in file:\n",
        "        method = 'baselinefast'\n",
        "    elif 'naive' in file:\n",
        "        method = 'baselinenaive'\n",
        "\n",
        "    df = pd.read_csv(file)\n",
        "    n = df['Number_of_nodes'].iloc[-1]\n",
        "    runtime = df['Run_time_in_ms'].iloc[-1]\n",
        "    accepted_events = df['Accepted_events'].iloc[-1]\n",
        "    runtime_per_step = runtime / accepted_events if accepted_events > 0 else 0\n",
        "\n",
        "    data_list.append((n, graph_type, method, runtime_per_step))\n",
        "\n",
        "# Extract unique values for graph types, methods, and node numbers\n",
        "graph_types = sorted(list(set([graph_type for n, graph_type, method, runtime_per_step in data_list])))\n",
        "methods = sorted(list(set([method for n, graph_type, method, runtime_per_step in data_list])))\n",
        "node_nums = sorted(list(set([n for n, graph_type, method, runtime_per_step in data_list])))\n",
        "\n",
        "# Use seaborn color palettes for blue, red, and green shades\n",
        "palette = sns.color_palette([\"#d62728\", \"#1f77b4\", \"#2ca02c\"])  # Red for ours, blue for baselinefast, green for baselinenaive\n",
        "\n",
        "# Map methods to colors and markers\n",
        "method_to_color = {\n",
        "    'ours': palette[0],  # Red\n",
        "    'baselinefast': palette[1],  # Blue\n",
        "    'baselinenaive': palette[2]  # Green\n",
        "}\n",
        "method_to_marker = {\n",
        "    'ours': '^',\n",
        "    'baselinefast': '>',\n",
        "    'baselinenaive': '<'\n",
        "}\n",
        "\n",
        "method_to_label = {\n",
        "    'ours': 'icon (ours)',\n",
        "    'baselinefast': 'Baseline (fast)',\n",
        "    'baselinenaive': 'Baseline (naive)'\n",
        "}\n",
        "\n",
        "# List to store final results\n",
        "final_results = []\n",
        "\n",
        "# Plotting data for each graph type\n",
        "for graph_type_i in graph_types:\n",
        "    plt.close()\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for method_i in methods:\n",
        "        for n_i in node_nums:\n",
        "            # Filter data points for the current graph_type, method, and node number\n",
        "            datapoints = [runtime_per_step for n, graph_type, method, runtime_per_step in data_list\n",
        "                          if n == n_i and method == method_i and graph_type == graph_type_i]\n",
        "            print(\"datapoints\", datapoints)  # Debugging output\n",
        "            if len(datapoints) == 0:\n",
        "                continue\n",
        "            runtime_mean = np.mean(datapoints)\n",
        "            runtime_std = np.std(datapoints) if len(datapoints) > 1 else 1.0\n",
        "            final = (graph_type_i, method_i, n_i, runtime_mean, runtime_std)\n",
        "            final_results.append(final)\n",
        "\n",
        "            # Plot scatter with different styles for 'ours' method\n",
        "            plt.scatter([n_i], [runtime_mean], s=100, edgecolors=method_to_color[method_i],\n",
        "                        facecolors='none', marker=method_to_marker[method_i], alpha=0.8,\n",
        "                        linewidths=3 if method_i == 'ours' else 2)\n",
        "\n",
        "    # Add dummy scatter plots for legend with hollow markers\n",
        "    for method_i in methods:\n",
        "        plt.scatter([], [], s=100, edgecolors=method_to_color[method_i], facecolors='none',\n",
        "                    marker=method_to_marker[method_i], label=method_to_label[method_i], linewidths=2)\n",
        "\n",
        "    # Set the x and y axis to logarithmic scale (log-log scale)\n",
        "    plt.xscale('log')\n",
        "    plt.yscale('log')\n",
        "\n",
        "    # Format the plot\n",
        "    plt.legend(title=\"Method\", loc='center left', bbox_to_anchor=(1, 0.5), frameon=False,\n",
        "               fontsize=22, title_fontsize=22)\n",
        "    format_plot(plt.gca(), f\"Runtime per Step for {graph_type_i.capitalize()} Graph\",\n",
        "                \"Number of Nodes\", \"Runtime per Step (ms)\")\n",
        "\n",
        "    # Save the plot\n",
        "    plt.savefig(f\"Scatter_{graph_type_i}_loglog_hollow.pdf\", bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# Print final results\n",
        "print(final_results)\n"
      ],
      "metadata": {
        "id": "kxrew1q4yHa7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}